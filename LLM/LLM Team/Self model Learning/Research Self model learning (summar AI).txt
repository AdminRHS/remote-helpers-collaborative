Ссылка на сравнение: https://docs.google.com/spreadsheets/d/1yWDoQ1OoJY-uJqxIgC8Di-1uhx-bTQPDU_wxgu7xvUY/
Подробный гайд как поставить и настроить модельку: https://docs.google.com/document/d/1FRuioKgiXsSNcTEgSnAAfWkKMjo6ofe1mVLaVn1HzC4/

# Итоговый обзор самообучающихся моделей

## 1. Введение

Современные системы машинного обучения сталкиваются с постоянно растущими объёмами данных и изменяющимися условиями. 
Самообучающиеся модели (self-learning) представляют собой подход, позволяющий моделям:
- **Автономно адаптироваться** к новым данным без полного переобучения с нуля.
- **Использовать обратную связь** из среды или собственных прогнозов для постоянного улучшения.
- **Минимизировать вмешательство человека** за счёт автоматизации процессов сбора, обработки и переобучения.

Эта концепция позволяет повысить точность, снизить затраты на ручное обновление и обеспечить устойчивость системы при 
изменении входных данных.

## 2. Основные подходы и типы моделей

### 2.1. Типы моделей самообучения
- **Автоэнкодеры**  
  Используются для снижения размерности, шумоподавления, обнаружения аномалий и извлечения признаков из неразмеченных данных.  
- **Генеративно-состязательные сети (GAN)**  
  Применяются для генерации новых реалистичных данных, увеличения объёма обучающей выборки и создания синтетических образцов.  
- **Обучение с подкреплением (RL)**  
  Модели обучаются через взаимодействие со средой, где агент получает награды или штрафы за свои действия, что позволяет 
  находить оптимальные стратегии.
- **NLP-модели (трансформеры, BERT, GPT, T5)**  
  Применяются для обработки текстовой информации: ответов на вопросы, классификации, извлечения сущностей и других языковых 
  задач.
- **Модели для табличных данных**  
  Классические алгоритмы градиентного бустинга (XGBoost, LightGBM, CatBoost) и нейросетевые подходы (MLP, TabNet, 
  TabTransformer) эффективны для прогнозирования на структурированных данных.
- **Модели для временных рядов**  
  Используются статистические методы (ARIMA, Prophet) и современные нейросетевые архитектуры (LSTM, Temporal Fusion 
  Transformer, N-BEATS) для прогнозирования с учётом сезонности и временной зависимости.

### 2.2. Подходы к самообучению (Self-learning / Semi-supervised)
- **Pseudo-labeling (самотренировка)**  
  Модель сначала обучается на небольшом размеченном наборе, затем генерирует метки для неразмеченных данных, что позволяет 
  расширить обучающую выборку.
- **Active Learning (активное обучение)**  
  Модель сама определяет, для каких примеров требуется ручная разметка, минимизируя затраты на аннотацию.
- **Онлайн-обучение (Continuous Training)**  
  Постоянное обновление модели по мере поступления новых данных без полного переобучения.
- **Parameter-Efficient Fine-Tuning (PEFT)**  
  Методы, позволяющие дообучать большую модель, обновляя лишь небольшую её часть, что ускоряет процесс адаптации.
- **Self-Supervised Pretraining**  
  Модель обучается на искусственно сформулированной задаче (например, маскированное предсказание слов) для извлечения полезных 
  представлений из данных.

## 3. Подготовка и обработка данных

- **Сбор данных:**  
  Использование исторических наборов, API, веб-скрейпинга, баз данных и облачных хранилищ.
- **Предварительная обработка:**  
  Очистка, нормализация, масштабирование и преобразование данных (как для изображений, так и для табличных и текстовых данных).
- **Инженерия признаков:**  
  Создание новых, более информативных признаков для улучшения качества обучения модели.
- **Обработка специфических данных:**  
  Для текстов – токенизация, извлечение эмбеддингов; для временных рядов – учет сезонности, трендов и аномалий.

## 4. Автоматизация и MLOps

Для обеспечения непрерывного обучения и минимального вмешательства человека важна автоматизация ключевых процессов:
- **Конвейеры данных:**  
  Автоматизированный сбор, подготовка и загрузка данных для обучения.
- **Мониторинг и оценка производительности:**  
  Отслеживание метрик качества модели, выявление data drift и concept drift с помощью специализированных инструментов 
  (Evidently, WhyLabs, Prometheus/Grafana).
- **Переобучение:**  
  Запуск процесса переобучения по расписанию или на основе триггеров, если производительность модели падает.
- **Развёртывание:**  
  Канареечное развёртывание, A/B тестирование и системы версионирования (MLflow, DVC) для безопасного обновления моделей.

## 5. Рекомендованные платформы и инструменты

### 5.1. Управляемые сервисы (AutoML платформы)
- **DataRobot:**  
  Поддержка автоматизированного переобучения с настройкой политик и триггеров.
- **AWS SageMaker:**  
  Использование Model Monitor и SageMaker Pipelines для автоматизации мониторинга и переобучения.
- **Google Cloud Vertex AI:**  
  Конвейеры для автоматического запуска переобучения на основе оповещений или расписания.
- **H2O Driverless AI:**  
  Функция AutoML Retrain для обновления модели без вмешательства пользователя.
- **Azure Machine Learning:**  
  Автоматизированное переобучение с мониторингом через управляемые онлайн-эндпоинты.

### 5.2. Открытые решения
- **MLflow:**  
  Система управления жизненным циклом моделей с возможностью интеграции с конвейерами переобучения.
- **Kubeflow:**  
  Платформа для автоматизации процессов обучения и развёртывания на Kubernetes.

### 5.3. Основные библиотеки и фреймворки
- **NLP и трансформеры:**  
  Hugging Face Transformers, PyTorch, TensorFlow, spaCy, Haystack, SentenceTransformers.
- **Табличные данные:**  
  XGBoost, LightGBM, CatBoost, Scikit-learn, AutoGluon, H2O AutoML.
- **Временные ряды:**  
  Statsmodels, Prophet, GluonTS, PyTorch Forecasting, Darts.

## 6. Заключение

Итоговая система самообучающихся моделей должна быть:
- **Модульной и масштабируемой:**  
  Отдельное обучение NLP-компонентов, моделей для структурированных данных и временных рядов.
- **Автоматизированной:**  
  Внедрение конвейеров для сбора, обработки и переобучения данных, мониторинг качества и автоматический запуск процессов.
- **Гибкой и адаптивной:**  
  Использование методов pseudo-labeling, active learning и онлайн-обучения для постоянного улучшения модели.
- **Поддерживаемой современными платформами:**  
  Выбор подходящего управляемого сервиса (DataRobot, AWS SageMaker, Vertex AI и т.д.) или открытых решений (MLflow, Kubeflow) 
  в зависимости от технических возможностей и требований пользователя.

Такой интегрированный подход позволяет создать систему, которая будет не только решать задачи по анализу текстовых и табличных 
данных, но и постоянно адаптироваться к изменениям в данных с минимальным участием человека.