# Подходы, инструменты и архитектуры для самообучающейся AI-модели (текст + структурированные данные)

## Введение  
Создание собственной самообучающейся модели искусственного интеллекта, способной работать как с текстовыми, так и 
с табличными (структурированными) данными, требует комплексного подхода. Необходимо спроектировать систему, которая 
будет: (1) отвечать на вопросы на основе предоставленного текста, (2) выполнять прогнозирование по структурированным 
данным, (3) обрабатывать и анализировать тексты (извлечение сущностей, классификация и т.д.), и (4) автоматически 
дообучаться на новых данных с минимальным участием человека. При этом предполагается отсутствие ограничений по 
вычислительным ресурсам и использование облачной инфраструктуры для развертывания решения. В данном отчёте рассматриваются 
подходящие архитектуры моделей, методы **self-learning** (самообучения), а также инструменты и фреймворки, обеспечивающие 
масштабируемость, устойчивость к изменению данных и автоматизацию процесса обучения.

## Задачи и требования  
**Ключевые задачи модели**:  
- **Ответы на текстовые вопросы** – модель должна извлекать ответы из текстовой информации (вопросно-ответная система, 
*Question Answering*).  
- **Прогнозирование по структурированным данным** – модель должна делать предсказания на основе табличных данных (например, 
временных рядов или совокупности признаков).  
- **Обработка текста** – выполнение NLP-задач: классификация текста, извлечение именованных сущностей (NER), тематический 
анализ и т.д.  
- **Самообучение** – способность автоматически дообучаться на новых (в том числе слабо размеченных или неразмеченных) данных 
с минимальным ручным вмешательством (self-learning или *semi-supervised learning*).

**Дополнительные условия**: модель будет развернута в облаке (offline-режим не требуется), ресурсы не ограничены, 
приоритет – высокая масштабируемость решения, устойчивость модели к изменению входных данных (концептуальный сдвиг, дрейф 
данных) и максимально автоматизированный конвейер обучения/переобучения.

## Архитектура решения (общий обзор)  
Учитывая разноплановость задач, целесообразно модульное архитектурное решение. На высоком уровне систему можно разделить 
на несколько компонентов:  

- **NLP-компонент (текстовая аналитика)**: отвечает за обработку текста, включая ответ на вопросы по текстам и другие 
языковые задачи. Здесь пригодны современные **Transformer**-модели, которые стали стандартом для NLP ([Transformers for Tabular Data Representation: A Survey of Models and Applications - ACL Anthology](https://aclanthology.org/2023.tacl-1.14/#:~:text=In%20the%20last%20few%20years%2C,each%20aspect%2C%20we%20characterize%20and)). 
Возможно использование отдельных специализированных моделей или единой многоцелевой модели для разных NLP-задач.  
- **Компонент прогнозирования по данным**: отвечает за анализ структурированных данных и прогнозирование. В зависимости от 
типа данных будут использоваться либо алгоритмы градиентного бустинга по деревьям для табличных данных, либо нейросетевые 
последовательностные модели (RNN, трансформеры) для временных рядов.  
- **База знаний и хранилище данных**: для ответов на вопросы может потребоваться хранилище документов или знаний (например, 
поисковый индекс или векторная база для семантического поиска), откуда NLP-модель будет извлекать нужную информацию. Для 
структурированных данных – хранилище исторических данных, используемых для переобучения модели.  
- **MLOps-инфраструктура**: конвейеры и сервисы, обеспечивающие автоматический сбор новых данных, мониторинг работы модели, 
обнаружение деградации качества и автоматический запуск дообучения. Это включает средства развёртывания в облаке, мониторинга 
дрейфа данных и производительности, а также механизмы Continuous Training (непрерывного обучения) ([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=Model%20retraining%20refers%20to%20updating,date%20data)).  

Модульная архитектура способствует масштабируемости – каждый компонент можно масштабировать и дообучать независимо. Например, 
при поступлении нового текста дообучается NLP-модель, а при накоплении новых структурированных данных переобучается модель 
прогнозирования. Облачное развертывание позволяет использовать необходимые вычислительные ресурсы (GPU/TPU для тяжелых моделей) 
и оркестрацию (например, Kubernetes для масштабирования сервисов). 

## Обработка текстовых данных (NLP-задачи)  
Для работы с текстом (вопросно-ответная система, классификация, NER и др.) на сегодняшний день **архитектуры на основе 
трансформеров** являются предпочтительными. Трансформеры (например, BERT, RoBERTa, GPT, T5 и их производные) 
продемонстрировали передовое качество в задачах понимания текста и вытеснили предыдущие рекуррентные сети (RNN, такие как 
LSTM/GRU) во многих приложениях ([Transformers for Tabular Data Representation: A Survey of Models and Applications - ACL Anthology](https://aclanthology.org/2023.tacl-1.14/#:~:text=In%20the%20last%20few%20years%2C,each%20aspect%2C%20we%20characterize%20and)). 
Ниже рассмотрены подходы к основным NLP-подзадачам модели: 

### Вопросно-ответная система (Machine Reading QA)  
Для ответа на вопросы по предоставленным текстам обычно применяются модели *Machine Reading Comprehension*. Классический 
подход – модель получает на вход вопрос и отрывок текста (контекст), а на выходе выдает текстовый ответ. Оптимальной 
архитектурой здесь является трансформер-энкодер с двухголовочной выходной слой для предсказания начала и конца ответа 
(как в BERT для SQuAD). Примеры: **BERT** или **RoBERTa**, дообученные на корпусах QA, способны находить ответ-фрагмент в 
тексте ([Question answering](https://huggingface.co/docs/transformers/en/tasks/question_answering#:~:text=Question%20answering%20tasks%20return%20an,types%20of%20question%20answering%20tasks)). 
Альтернативно можно использовать **генеративные модели** (например, T5, GPT-3/4) для формулировки ответа, что особенно 
полезно для открытых вопросов.  

**Инструменты и библиотеки для QA**:  
- *Hugging Face Transformers* – предоставляет готовые модели вопрос-ответ (*QuestionAnsweringPipeline*) и сотни предобученных 
весов (например, `bert-large-uncased-whole-word-masking-finetuned-squad` для экстрактивного QA). С использованием этой 
библиотеки можно легко загрузить предобученную модель и адаптировать её под свои данные. Преимущество – сообщество и 
поддержка производства: такие модели уже применяются в крупных компаниях ([Text classification](https://huggingface.co/docs/transformers/en/tasks/sequence_classification#:~:text=Text%20classification%20is%20a%20common,assigns%20a%20label%20like%20positive)).  
- *Haystack (deepset.ai)* – открытый фреймворк для построения QA-систем, сочетающий поиск по базе документов и чтение ответа 
трансформером. Haystack позволяет выстраивать конвейеры с компонентами: **Retriever** (например, Elasticsearch, Milvus для 
векторного поиска) для поиска релевантных документов по вопросу и **Reader** (например, модель на основе BERT) для извлечения 
ответа из найденного текста. Этот инструмент особенно полезен, если объем знаний большой и требуется сначала найти нужный 
контекст. (Haystack поддерживает различные модели трансформеров для поиска и ответа, а также интеграцию с популярными 
векторными хранилищами).  
- *Deep Learning фреймворки* – **PyTorch** и **TensorFlow**. Поскольку ресурсы не ограничены, можно использовать PyTorch для 
гибкости и поддержки со стороны HuggingFace. PyTorch Lightning облегчит организацию тренингового кода и масштабирование 
обучения на нескольких GPU. В TensorFlow также есть готовые модели (Keras-hub) для QA, но сообществом NLP более широко 
сейчас используется PyTorch+Transformers.  

**Подход к self-learning для QA**: Самообучение в контексте QA может осуществляться путем постоянного дополнения корпуса и 
дообучения модели. Например, если в систему поступают новые документы, они автоматически добавляются в индекс, а модель 
периодически дообучается на новых *вопрос-ответ* парах. Генерация псевдо-разметки также возможна: с помощью крупной языковой 
модели можно автоматически сгенерировать вопросы к новым текстам и использовать их как дополнительное обучение (подход 
*Generative Pseudo-Labeling* для доменной адаптации QA). Кроме того, можно собирать **обратную связь** от пользователей 
(например, рейтинг ответов) и на её основе корректировать модель через дообучение или алгоритмы подкрепления (RLHF – 
*reinforcement learning from human feedback*, если объем данных обратной связи достаточен).

### Анализ и обработка текстов (классификация, NER и др.)  
Помимо QA, модель должна выполнять общие задачи NLP: классифицировать тексты, извлекать сущности, определять тональность 
и т.п. **Трансформеры-энкодеры** также являются лучшим выбором здесь. Как правило, архитектура представляет собой 
предобученный энкодер (например, **BERT** или более новая модель вроде **XLM-R** для мультиязычной поддержки) с выходным 
слоем, настроенным под нужную задачу: классификационный (softmax) для меток класса или токен-классификационный (для NER 
метки на каждый токен). 

**Ключевые технологии для NLP-задач**:  
- *Transfer Learning* с предобученными моделями: Использование моделей, предварительно обученных на огромных объемах текста, 
и их **fine-tuning** на конкретных задачах резко повышает качество и снижает требования к объему размеченных данных. Например, 
модель BERT уже содержит знания о языке, и требуется лишь небольшое дообучение на датасете по классификации (или NER), чтобы 
достичь высокой точности. Такие модели обучены методом **self-supervised** (маскированное моделирование языка и др.), что по 
сути является формой самообучения на неразмеченных данных.  
- **Hugging Face Transformers** – основной фреймворк для работы с трансформерами. Он поддерживает задачи 
*Sequence Classification*, *Token Classification* и др. Например, класс `BertForSequenceClassification` легко fine-tune для 
задач классификации (тематической, сентимент-анализа и т.д.), а `BertForTokenClassification` – для именованных сущностей. 
HuggingFace предоставляет единообразный интерфейс и готовые веса моделей, что существенно ускоряет разработку. *Пример*: 
«Text classification is a common NLP task ... Some of the largest companies run text classification in production... одна 
из самых популярных форм – анализ тональности» ([Text classification](https://huggingface.co/docs/transformers/en/tasks/sequence_classification#:~:text=Text%20classification%20is%20a%20common,assigns%20a%20label%20like%20positive)) – 
это подтверждает, что такие модели уже промышленно применяются.  
- **spaCy** – библиотека для NLP с предобученными пайплайнами. Она особенно удобна для быстрого извлечения сущностей (NER), 
частей речи и пр. SpaCy можно рассмотреть для тех случаев, когда нужна готовая производительная реализация на основе 
трансформера (например, модель `en_core_web_trf` включает трансформер). Однако обучение новых моделей в spaCy менее гибкое, 
чем в HuggingFace, поэтому для кастомных self-learning сценариев (дообучение на новых данных) HuggingFace предпочтительнее. 
Тем не менее, spaCy поддерживает интеграцию с моделями из Transformers для inference ([Using spaCy at Hugging Face](https://huggingface.co/docs/hub/en/spacy#:~:text=spaCy%20makes%20it%20easy%20to,and%20lets%20you%20build)).  
- **SentenceTransformers** – надстройка над HuggingFace для получения эмбеддингов предложений/текстов. Может быть полезна, 
если понадобятся семантические представления текста (например, для кластеризации документов или поиска похожих запросов).  

**Self-learning в текстовых задачах**:  
- *Pseudo-labeling* (псевдо-разметка) для текстов: Модель, обученная на небольшом размеченном корпусе, применяется к большому 
неразмеченному корпусу текстов, чтобы присвоить им предположительные метки, после чего модель дообучается уже на расширенном 
наборе данных. Этот подход известен как **самотренировка (self-training)** и позволяет задействовать неразмеченные данные 
([Pseudo Labeling: Leveraging the Power of Self-Supervision in Machine Learning | by Data Overload | Medium](https://medium.com/@data-overload/pseudo-labeling-leveraging-the-power-of-self-supervision-in-machine-learning-d8192e918d65#:~:text=Pseudo%20labeling%2C%20also%20known%20as,predictions%20and%20improve%20over%20time)). 
Например, если есть множество документов без меток тем, изначально обученная модель классификации тем может разметить их и 
включить в обучение, улучшив тем самым свою точность. В задачах NER похожий подход сложнее из-за высокой чувствительности к 
качеству разметки, но возможны итеративные схемы: отбирать с высокой уверенностью распознанные сущности как новые тренинговые 
примеры.  
- *Active Learning* (активное обучение): хотя строго говоря это не полностью автоматическое самообучение, данный подход 
минимизирует ручной труд. Модель сама выявляет примеры, в которых она наиболее неуверена, и запрашивает у эксперта метки 
только для этих “трудных” случаев. В продакшене можно реализовать так: модель обрабатывает поток текстов, и если её 
уверенность в классификации ниже определенного порога, этот текст отправляется в очередь на разметку. Так человек учавствует 
только точечно, а основная масса данных обрабатывается автоматически. Существуют библиотеки (например, **modAL** для Python) 
для реализации стратегий активного обучения.  
- *Продолжение предобучения* (*continual pre-training*): для адаптации к новым данным модель языка можно дообучать на новых 
корпусах без меток. Например, если язык запросов пользователей со временем меняется, можно периодически выполнять 
дополнительный *masked language modeling* на свежих текстах, чтобы обновлять внутренние представления модели без явных меток. 
Это позволяет модели «самообучаться» сохранять актуальность языковых знаний. Важно при этом избегать **катастрофического 
забывания** – техники вроде *Elastic Weight Consolidation* или опыт непрерывного обучения (**continual learning**) могут 
быть полезны.  
- *Parameter-Efficient Fine-Tuning (PEFT)*: при регулярном дообучении больших моделей имеет смысл использовать методы 
частичного обновления параметров. Библиотека HuggingFace **PEFT** предлагает методы адаптации LLM, где обучается лишь 
небольшой процент параметров (например, добавочные слои-адаптеры или веса Лора), что упрощает и ускоряет частые дообучения 
([PEFT](https://huggingface.co/docs/peft/en/index#:~:text=PEFT%20%28Parameter,LLMs%29%20on%20consumer%20hardware)). Такой 
подход позволит оперативно подстраивать большую языковую модель под новые данные, не выполняя полную дорогую тренировку 
заново, и хранить лишь «дельта»-модификации.  

## Прогнозирование на структурированных данных  
Задачи прогнозирования по табличным данным могут включать предсказание метрик бизнеса, анализ временных рядов (например, 
прогноз продаж по времени), либо предсказание целевой переменной по совокупности признаков (классификация/регрессия по 
табличным данным). Эти задачи существенно отличаются от NLP, поэтому используются иные модели и библиотеки. Ниже рассмотрены 
два основных сценария: **табличные данные общего вида** и **временные ряды**.  

### Модели для табличных (структурированных) данных  
Для табличных данных с зафиксированным набором признаков классическим и проверенным решением являются **алгоритмы градиентного 
бустинга** (GBM) на решающих деревьях: прежде всего, **XGBoost**, **LightGBM**, а также **CatBoost** (последний особенно хорош 
на данных с категориальными признаками). Эти модели часто дают наилучшие результаты в задачах табличного прогнозирования 
благодаря способности выявлять нелинейные зависимости и устойчивости к шуму. Они широко используются на практике и содержатся 
в арсенале AutoML-систем. Даже по состоянию на 2025 год, во многих промышленных решениях и соревнованиях качество бустинговых 
моделей сопоставимо или выше, чем у глубоких нейросетей на тех же данных, особенно при относительно небольших объемах данных 
или смешанных типах признаков (числовые, категориальные). 

**Инструменты для GBM**:  
- **XGBoost** – библиотека на C++/Python, реализующая экстремальный градиентный бустинг. Обладает возможностями параллелизации, 
отлично масштабируется и имеет Python API (обертка `xgboost`). Хорошо подходит для наших целей прогнозирования метрик, т.к. 
поддерживает и регрессию, и классификацию, а также дает показатели важности признаков для интерпретации.  
- **LightGBM** – библиотека от Microsoft, альтернативная реализация бустинга, часто быстрее XGBoost на больших данных за счет 
специальных оптимизаций (например, усечение по листьям дерева). Также поддерживает GPU-ускорение.  
- **CatBoost** – библиотека от Яндекса, особо эффективна при наличии категориальных признаков (встроенное кодирование 
категорий), иногда показывает лучшее качество без тщательного тюнинга.  

**Глубокие нейросети для табличных данных**: При отсутствии ограничений по ресурсам можно рассмотреть **нейросетевые модели**, 
особенно если объем данных очень велик или нужно объединять гетерогенные источники данных. Примеры архитектур:  
- **Многослойный персептрон (MLP)** – простой полносвязный нейросетевой регрессор/классификатор. Требует тщательной настройки 
и большого количества данных, чтобы превзойти бустинг. Может дополнительно выигрывать, если данные обновляются постоянно 
(нейросеть можно дообучивать по чуть-чуть, реализуя online learning).  
- **TabNet** – архитектура от Google, использующая механизм feature attention для табличных данных. Позволяет моделям 
автоматически выбирать, на какие признаки обращать внимание на каждой итерации.  
- **TabTransformer** – архитектура на основе трансформера, предложенная AWS, в которой категориальные признаки преобразуются 
в эмбеддинги и обрабатываются блоком Transformer для выявления связей между признаками. Исследования последних лет активно 
изучают применение трансформеров к табличным данным ([Transformers for Tabular Data Representation: A Survey of Models and 
Applications - ACL Anthology](https://aclanthology.org/2023.tacl-1.14/#:~:text=In%20the%20last%20few%20years%2C,each%20aspect%2C%20we%20characterize%20and)), 
чтобы объединить преимущества глубоких моделей и способность работать с разными типами признаков.  
- **Автоэнкодеры и представления** – можно обучить автоэнкодер на таблицах, чтобы получить сжатое представление признаков, а 
затем использовать его для основной задачи (или для детекции аномалий). Это форма самообучения (self-supervised) на 
структурированных данных.  

На практике, нейросети для табличных данных пока редко значительно превосходят градиентный бустинг, если не задействовать 
дополнительные данные или сложные схемы. Поэтому разумным подходом может быть **ансамблирование** – например, объединить 
предсказания бустинга и простой нейросети или нескольких моделей (это умеют некоторые AutoML). 

**AutoML для табличных данных**: Стоит упомянуть автоматизированные инструменты, которые сами подберут лучший алгоритм:  
- **AutoGluon (Tabular)** – фреймворк от AWS, который автоматически тренирует ансамбль моделей (GBM, нейросети, k-NN и др.) 
на табличных данных и выбирает оптимальное. Он поддерживает также текстовые поля как специальные признаки – то есть может 
одновременно обработать таблицу с колонками текста, применяя под капотом трансформеры для текстовых полей и объединяя с 
остальными признаками. Это ценно, если данные мультимодальные.  
- **H2O.ai AutoML** – коммерческий и open-source инструмент, перебирающий множество моделей (GBM, GLM, Deep Learning и др.) 
и делающий стэкинг.  
- **Google Cloud AutoML Tables / Vertex AI** – облачная AutoML-система для табличных данных: пользователь загружает данные, 
а сервис подбирает и обучает модель (в т.ч. DNN, ансамбли) с минимальным кодом.  
- **PyCaret** – библиотека в Python, упрощающая обучение и сравнение моделей на табличных данных. Может быстро показать 
baseline-модель и позволяет легко внедрять новые данные для дообучения.  

### Модели для временных рядов (прогнозирование по времени)  
Если структура данных подразумевает временной ряд (например, ежедневные продажи, метрика по времени), задача прогнозирования 
имеет специфику учета временной зависимости и сезонности. Подходы делятся на статистические модели и глубокое обучение:  

- **Классические статистические методы**: ARIMA, SARIMA, ETS (экспоненциальное сглаживание) – хорошо работают на одномерных 
временных рядах при достаточной стационарности. Библиотеки: `statsmodels` (Python) содержит ARIMA/ETS, а **Prophet** (от Meta) 
предоставляет простое в использовании средство для бизнес-временных рядов, учитывающее сезонность, выходные и т.д. Prophet 
может быть полезен как baseline-модель.  
- **Рекуррентные нейросети**: LSTM и GRU активно применялись для прогнозирования временных рядов, особенно многомерных, где 
на вход подается окно значений, а на выходе – прогноз будущих точек. RNN умеют учитывать последовательность, но плохо 
параллелятся и могут уступать более новым архитектурам.  
- **Transformer для временных рядов**: последнее поколение моделей использует механизм внимания для учета длительных 
зависимостей. Пример – **Temporal Fusion Transformer (TFT)**, архитектура для интерпретируемого прогноза множественных 
временных рядов. В исследовании эта модель превзошла предшественников (так, сообщается об улучшении качества на **36–69%** 
по сравнению с Amazon DeepAR на ряде бенчмарков ([TemporalFusionTransformer — pytorch-forecasting  documentation](https://pytorch-forecasting.readthedocs.io/en/v1.2.0/api/pytorch_forecasting.models.temporal_fusion_transformer.TemporalFusionTransformer.html#:~:text=Implementation%20of%20the%20article%20Temporal,69%25%20in%20benchmarks))). 
TFT комбинирует LSTM для локального учета последовательности и слой внимания для агрегирования информации, а также 
предоставляет интерпретируемость (важность переменных и т.п.).  
- **Другие модели**: N-BEATS (Neural Basis Expansion) – глубокая архитектура для прогноза, показавшая state-of-the-art на 
некоторых соревнованиях, CNN для временных рядов (TCN – temporal convolutional networks) и др. С развитием исследований, 
нейросетевые модели всё чаще включаются в библиотеки прогнозирования.  

**Инструментарий для временных рядов**:  
- **GluonTS** – библиотека от AWS (ранее на MXNet, сейчас есть и PyTorch backend), включающая набор моделей для 
прогнозирования: от простых (наивные, пропорциональные) до DeepAR, WaveNet, Transformer. Она также поддерживает оценку 
неопределенности прогноза (выдает распределение).  
- **PyTorch Forecasting** – надстройка над PyTorch Lightning, содержащая реализации популярных моделей, включая Temporal 
Fusion Transformer, DeepAR, CNN и др. С ее помощью можно быстро обучить сложную модель и воспользоваться готовыми примерами.  
- **Darts** – универсальная Python-библиотека от компании Unit8, предлагающая единый интерфейс для множества моделей 
прогнозирования (ARIMA, Prophet, FFT, RNN, Transformer и др.). Она удобна тем, что позволяет легко пробовать разные подходы 
и даже комбинировать их (ансамбли, смешанные прогнозы).  
- **StatsForecast (Nixtla)** – новый набор инструментов, оптимизированных для масштабного обучения моделей прогнозов 
(в том числе статистических) на многих рядах одновременно с высокой производительностью.  

Выбор конкретного подхода для прогнозирования зависит от природы данных. Если данных немного и они хорошо размечены, имеет 
смысл начать с простых моделей (ARIMA, Prophet) и базовых ML (например, XGBoost по признакам, извлеченным из временного окна). 
Если данных много или требуется учитывать множество факторов и зависимостей, тогда оправдано использование нейросетей 
(LSTM/Transformer). Поскольку ресурсы не лимитированы, можно позволить тяжелую модель и сравнить результаты. Важным моментом 
будет **устойчивость модели к смене данных**: временные ряды часто подвержены концептуальному сдвигу (смена тренда, новое 
поведение пользователей). Поэтому далее рассматриваются стратегии мониторинга и автоматического переобучения. 

## Подходы к самообучению (semi-supervised learning)  
Самообучение модели – это способность использовать неразмеченные или свежие данные для улучшения своих навыков без полного 
ручного переобучения. Ниже перечислены основные подходы, позволяющие реализовать self-learning или **semi-supervised** 
обучение:  

- **Pseudo-labeling (самотренировка)** – один из самых популярных подходов. Алгоритм: сначала модель обучается на небольшом 
наборе размеченных данных, затем применяется к большому массиву неразмеченных данных, чтобы спрогнозировать (сгенерировать) 
для них метки. Эти *псевдо-метки* добавляются в обучающую выборку, и модель повторно обучается уже на расширенном датасете 
([Pseudo Labeling: Leveraging the Power of Self-Supervision in Machine Learning | by Data Overload | Medium](https://medium.com/@data-overload/pseudo-labeling-leveraging-the-power-of-self-supervision-in-machine-learning-d8192e918d65#:~:text=Pseudo%20labeling%2C%20also%20known%20as,predictions%20and%20improve%20over%20time)). 
Процесс может повторяться итеративно. Этот метод успешно применяется в классификации текста, анализе тональности, 
распознавании изображений и др., позволяя эффективно задействовать дешевые неразмеченные данные. **Важные моменты**: нужно 
отбирать высоко уверенные прогнозы модели, чтобы не вносить шум; можно постепенно усложнять задачи, давая модели новые данные 
по мере улучшения. Несмотря на риск накопления ошибок, при правильной настройке pseudo-labeling существенно повышает качество, 
приближая его к обучению на полном объеме данных.  
- **Self-Supervised Pretraining (самостоятельное предобучение)** – использование свойств самих данных для обучения. Примеры: 
маскированное предсказание слов в тексте (как в BERT) или восстановление пропущенных частей временного ряда. Модель обучается 
решать искусственно сформулированную задачу, которая не требует ручных меток, тем самым извлекая полезные представления. 
Затем эти представления используются для основной задачи. Для нашей системы это означает, что мы можем предварительно обучить 
модель на любом имеющемся сыром тексте (обучить языковую модель) или на неразмеченных временных рядах (обучить автоэнкодер, 
предсказывающий следующие точки), прежде чем обучать на целевую переменную. Такой подход улучшает устойчивость к недостатку 
данных и изменению распределения – модель как бы *учится учиться* из структуры данных.  
- **Active Learning** – как упоминалось, это полуавтоматический метод. Модель активно запрашивает метки только для наиболее 
информативных примеров. С точки зрения всей системы, это встроенный цикл: модель помечает, какие новые данные она не уверена 
как обрабатывать, и человек (эксперт) минимум времени тратит на помощь модели. В результате за несколько итераций модель 
обучается на примерах, которые она сама выбрала, существенно сокращая объем ручной разметки. В условиях минимального 
вмешательства человека, активное обучение – ценный компромисс.  
- **Онлайн-обучение (online learning)** – постоянное обновление модели по мере поступления новых данных, зачастую покроково. 
Некоторые алгоритмы поддерживают частичное дообучение (*partial_fit* в scikit-learn для линейных моделей, Naive Bayes и др.). 
В контексте нейросетей online learning достигается либо очень частым переобучением на новом пакете данных, либо использованием 
потоковых архитектур (например, рекуррентные сети, которые продолжают обучение, получая новые последовательности). Для нашей 
самообучающейся системы это означает, что как только появляется новая порция обучающих данных (например, новые примеры с 
известным ответом или новые временные точки с известным исходом), модель сразу обновляет свои веса, без запуска 
полномасштабного обучения с нуля. Такой режим обеспечивает модель всегда актуальными знаниями и быстро реагирует на 
изменения данных. Однако нужно учитывать *drift* (смещение данных) – если данные со временем меняются, online-обучение без 
должного контроля может закрепить в модели устаревшие зависимости.  
- **Knowledge Distillation и Teacher-Student** – подход, когда более мощная модель (или ансамбль моделей) используется для 
генерации ответов/предсказаний, которыми затем обучается более простая модель. В нашем случае, если доступны очень большие 
предобученные модели (например, GPT-4 via API) для некоторых задач, можно собрать обширный псевдо-размеченный набор, а затем 
обучить свою компактную модель, используя ответы этой *teacher*-модели как истину. Это частный случай self-learning, где роль 
«самообучения» выполняет знание, переданное от одной модели другой.  

На практике, самообучающаяся система может комбинировать несколько подходов. Например, модель классификации текста может 
работать в цикле: раз в неделю брать накопленные неразмеченные пользователями тексты, помечать их своим текущим вариантом 
(pseudo-label), отфильтровывать неуверенные, добавлять наиболее надежные в тренировочный сет и дообучаться. Одновременно, 
при обнаружении, что распределение новых текстов сильно сместилось (например, появились новые темы или жаргон), можно 
инициировать дополнительное **предобучение языковой модели** на этом новом корпусе, чтобы обновить эмбеддинги. Все это 
должно происходить автоматически, без ручного анализа каждого шага – именно поэтому важно интегрировать эти процессы с 
**MLOps-конвейером**. Ниже рассмотрены инструменты для мониторинга и автоматического переобучения модели.

## MLOps: мониторинг, автоматическое переобучение и развёртывание  
Для промышленной эксплуатации самообучающейся модели необходимы процессы MLOps – мониторинг качества, управление версиями 
модели, автоматический запуск переобучения и надежное развертывание. Учитывая приоритет на **масштабируемость** и 
**устойчивость к изменению данных**, мы выделяем следующие рекомендации:

- **Мониторинг производительности и дрейфа данных**: После развёртывания модели важно отслеживать, не ухудшается ли её 
качество со временем. *Model drift* – явление деградации модели из-за изменения входящих данных или скрытых зависимостей 
([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=is%20called%20model%20drift%20and,in%20production%20provide%20healthy%20results)). 
Существуют два типа дрейфа: **concept drift** (изменение самой зависимости между признаками и целевой переменной) и 
**data drift** (изменение распределения входных признаков) ([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=There%20are%20two%20main%20model,drift%20types)). 
Необходимо мониторить оба. Инструменты:  
  - Метрики качества на контрольной выборке в продакшене (если есть возможность периодически сверять с истинными значениями).  
  - **Evidently AI**, **WhyLogs/WhyLabs** – открытые инструменты для мониторинга статистики данных. Они могут вычислять 
  расстояния между распределениями (например, KL-дивергенция, PSI) текущих данных и обучающей выборки, выявлять значимые 
  отклонения. WhyLabs, например, позволяет настроить алерты при дрейфе признаков или отклонении выходов модели.  
  - Логирование всех прогнозов и пришедших впоследствии истинных значений (для структурированных данных: фактические 
  результаты прогнозов, для NLP: возможно, пользовательский фидбэк). Это данные затем используются для ретроспективной 
  оценки качества.  

- **Плановое переобучение (Retraining)**: Нужно определить стратегию, **когда и как переобучать модель**. Возможны подходы:  
  - *Периодическое переобучение*: например, раз в N недель/месяцев модель переобучается на самых свежих данных. Это простой и 
  надежный график, особенно если данные постоянно прибавляются.  
  - *Триггер на основе дрейфа/метрик*: при снижении качества ниже порога или при детекции значимого дрейфа входных данных 
  запускается внеплановое переобучение. Например, если распределение новых категориальных признаков сильно отличается от 
  обучающего (новые значения полей или смена сезонности во временном ряду), стоит обновить модель.  
  - *Непрерывное обучение (Continuous Training, CT)*: интеграция процесса обучения в конвейер CI/CD. Google Cloud предлагает 
  концепцию CI/CD/CT, где Continuous Training – автоматическое обновление модели при поступлении новых данных 
  ([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=Model%20retraining%20refers%20to%20updating,date%20data)). 
  Такая система может быть реализована с помощью **Kubeflow Pipelines** или облачных оркестраций (AWS SageMaker Pipelines, 
  GCP Vertex AI Pipelines). По сути, новые данные триггерят запуск pipeline: подготовка данных → обучение модели → оценка 
  качества → развёртывание новой версии (при условии, что качество улучшилось).  

- **Валидация и развёртывание новой модели**: После переобучения важно убедиться, что новая модель действительно лучше и не 
имеет регрессий. Рекомендуется автоматизировать:  
  - Держать *hold-out* выборку или использовать кросс-валидацию при каждом обучении и сравнивать метрики новой и текущей 
  моделей.  
  - В продакшене применять стратегию **канареечного развёртывания** или A/B тестирования: новую модель запустить на небольшой 
  доле трафика и сравнить показатели (точность ответов, CTR, пользовательские оценки и т.п.) с предыдущей версией. Только 
  затем постепенно увеличить долю или полностью заменить старую модель.  
  - Использовать системы версионирования моделей (**MLflow**, **DVC** – Data Version Control) для отслеживания, какая версия 
  модели когда обучена, на каких данных и с какими метриками. Это позволит откатиться в случае проблем.  

- **Устойчивость и отказоустойчивость**: Внедряя самообучение, следует предусмотреть механизмы, если автоматическое обучение 
пошло не так (например, если новые данные оказались некорректными и модель ухудшилась). Решения: хранить копию старой модели 
до полной проверки новой, использовать *ensembling* – например, брать усредненное решение старой и новой моделей в первые дни 
работы новой модели. Также полезно иметь сигналы мониторинга качества (скажем, доля уверенных ответов модели, или число 
случаев, когда модель отказалась отвечать) – резкие изменения таких сигналов могут указывать на проблему.  

- **Инфраструктура развертывания в облаке**:  
  - Развернуть модели можно в виде микросервисов (например, REST API, gRPC) в Kubernetes кластере для масштабирования по 
  запросам. Пакетировать модель и окружение в **Docker** – стандартный подход. Фреймворк **TensorFlow Serving** или 
  **TorchServe** может облегчить публикацию моделей как сервисов.  
  - Для высоконагруженных систем можно использовать специализированные серверы, например, **NVIDIA Triton Inference Server**, 
  позволяющий обслуживать несколько моделей (даже разных фреймворков) эффективно на GPU, или **FastAPI/Uvicorn** для быстрого 
  REST сервиса.  
  - Облачные провайдеры предлагают управляемые сервисы: **AWS SageMaker Endpoints**, **GCP Vertex AI Endpoints** – куда можно 
  выложить модель и автоматически масштабировать инфраструктуру по нагрузке, получать мониторинг вызовов и пр. С учётом 
  отсутствия ограничений по ресурсам, можно задействовать автопилотируемые сервисы, что снизит операционные усилия.  

- **Пример реализации Continuous Training**:  
  Допустим, у нас модель прогнозирует спрос на основе табличных данных. Организуется ежедневный джоб, который собирает 
  вчерашние фактические данные продаж, добавляет их к обучающему датасету и переобучает модель (либо выполняет одну эпоху 
  обучения продолжая с текущих весов, если используем нейросеть). После этого скрипт оценивает модель на последней неделе 
  данных: если ошибка стала ниже, новая модель регистрируется в реестре моделей и автоматически деплоится. В противном 
  случае – отклоняется, а оповещение отправляется разработчикам. Такой конвейер может быть реализован средствами 
  MLOps-платформы (например, **MLflow** + **Apache Airflow** или Kubeflow). Итог – минимальное участие человека, модель 
  сама подстраивается под новые реалии данных. 

## Рекомендуемые технологии и фреймворки (сводка)  
Ниже приведена сводная таблица с основными технологиями, соответствующими каждой категории задач и процессов нашей 
самообучающейся AI-модели:

===========================================================================================================================
link: https://docs.google.com/spreadsheets/d/1yWDoQ1OoJY-uJqxIgC8Di-1uhx-bTQPDU_wxgu7xvUY/edit?gid=0#gid=0
| **Категория**                     | **Технологии / инструменты**                                           | **Назначение и примечания**                                       |
|-----------------------------------|------------------------------------------------------------------------|--------------------------------------------------------------------|
| **Архитектуры моделей (AI)**      | • **Трансформеры** (BERT, RoBERTa, GPT, T5 и др.)<br>• **RNN** (LSTM, GRU) для последовательностей<br>• **Gradient Boosting** (XGBoost, LightGBM, CatBoost)<br>• **CNN/MLP** для специальных случаев | Transformers – современный стандарт для NLP-задач (понимание текста, QA, классификация) ([Transformers for Tabular Data Representation: A Survey of Models and Applications - ACL Anthology](https://aclanthology.org/2023.tacl-1.14/#:~:text=In%20the%20last%20few%20years%2C,each%20aspect%2C%20we%20characterize%20and)). RNN – для временных рядов и старых NLP-подходов (уступают трансформерам). Бустинг по деревьям – лучший выбор для статических табличных данных. CNN/MLP – используются в специализированных сценариях (например, 1D-CNN для некоторых временных рядов). |
| **NLP фреймворки и библиотеки**   | • **PyTorch** + **Hugging Face Transformers**<br>• **TensorFlow/Keras** (альтернатива)<br>• **spaCy** (готовые NLP модели)<br>• **Haystack** (QA-системы)<br>• **SentenceTransformers** | PyTorch с HuggingFace – де-факто стандарт разработки кастомных NLP моделей, дающий доступ к предобученным моделям и удобным средствам тонкой настройки ([Text classification](https://huggingface.co/docs/transformers/en/tasks/sequence_classification#:~:text=Text%20classification%20is%20a%20common,assigns%20a%20label%20like%20positive)). TensorFlow также возможен, но сообщество NLP смещается к PyTorch. SpaCy – для быстрого развёртывания NER/токенизации. Haystack – фреймворк для конвейеров вопрос-ответ (поиск + читатель). SentenceTransformers – получение эмбеддингов текста для семантических задач (например, поиск похожих вопросов). |
| **Инструменты для табличных данных** | • **Scikit-learn** (базовые модели)<br>• **XGBoost, LightGBM, CatBoost**<br>• **PyTorch/TensorFlow** (нейросети для табличных)<br>• **AutoGluon**, **H2O AutoML** | Scikit-learn – базовые алгоритмы (линейные модели, SVM, деревья) для табличных данных и как составляющие ансамблей. XGBoost/LightGBM/CatBoost – высокопроизводительные реализации градиентного бустинга, ключевые для качественного прогнозирования на структурированных данных. Фреймворки DL (PyTorch/TensorFlow) – если решено строить нейросеть для таблиц (например, TabTransformer). AutoML инструменты – автоматический подбор и ансамблирование моделей, полезны для ускорения экспериментов. |
| **Инструменты для временных рядов** | • **statsmodels** (ARIMA и др.)<br>• **Prophet** (простой прогноз)<br>• **GluonTS** (AWS)<br>• **PyTorch Forecasting**, **Darts** | Statsmodels – статистические модели временных рядов (задаёт базовый уровень). Prophet – быстрый прототипирование прогноза с сезонностями. GluonTS – набор продвинутых моделей (DeepAR, Prophet, Transformer) в едином фреймворке с оценкой неопределенности. PyTorch Forecasting – реализует современный TFT и др. модели; согласно документации, TFT значительно превосходит классические подходы (до **36-69%** лучше DeepAR) ([TemporalFusionTransformer — pytorch-forecasting  documentation](https://pytorch-forecasting.readthedocs.io/en/v1.2.0/api/pytorch_forecasting.models.temporal_fusion_transformer.TemporalFusionTransformer.html#:~:text=Implementation%20of%20the%20article%20Temporal,69%25%20in%20benchmarks)). Darts – универсальный высокоуровневый API для множества моделей, позволяет комбинировать методы. |
| **Self-learning / Semi-supervised** | • **Pseudo-labeling** (итеративное самодообучение)<br>• **Active Learning** (например, modAL)<br>• **HuggingFace PEFT** (эффективный fine-tune)<br>• **Continual Learning libs** (например, Avalanche)<br>• **Snorkel** (Weak Supervision) | Pseudo-labeling – модель обучается на своих же прогнозах для расширения обучающих данных ([Pseudo Labeling: Leveraging the Power of Self-Supervision in Machine Learning | by Data Overload | Medium](https://medium.com/@data-overload/pseudo-labeling-leveraging-the-power-of-self-supervision-in-machine-learning-d8192e918d65#:~:text=Pseudo%20labeling%2C%20also%20known%20as,predictions%20and%20improve%20over%20time)). Active Learning – модель выявляет, на чем учиться, человек минимально помогает. PEFT – позволяет быстро дообучивать большие модели, обучая лишь малую долю параметров ([PEFT](https://huggingface.co/docs/peft/en/index#:~:text=PEFT%20%28Parameter,LLMs%29%20on%20consumer%20hardware)), что идеально для частых обновлений. Continual learning библиотеки (Avalanche) – для исследовательских подходов по постепенному обучению без забывания. Snorkel – платформа слабого контроля, генерирует метки на основе правил и моделей, может дополнить self-learning, автоматически размечая данные. |
| **MLOps и мониторинг**           | • **MLflow, DVC** (версии и эксперименты)<br>• **Kubeflow, Airflow** (автоматизация пайплайнов)<br>• **Evidently**, **WhyLabs** (мониторинг дрейфа)<br>• **Prometheus/Grafana** (метрики продакшена)<br>• **CI/CD/CT** (SageMaker Pipelines, Vertex AI) | MLflow/DVC – трекинг параметров, версионность датасетов и моделей, воспроизводимость. Kubeflow/Airflow – оркестрация процессов обучения/развертывания (например, конвейер ежедневного обновления модели). Средства мониторинга: Evidently, WhyLabs – автоматически вычисляют метрики данных/моделей и сигнализируют о дрейфе входных данных или ухудшении качества ([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=There%20are%20two%20main%20model,drift%20types)). Prometheus/Grafana – метрики сервисов (время ответа, ошибки) и кастомные метрики модели. Интеграция с CI/CD: SageMaker Pipelines или Vertex AI позволяют реализовать **Continuous Training** – отслеживать новые данные и триггерить обучение в автоматическом режиме ([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=Model%20retraining%20refers%20to%20updating,date%20data)). |
===========================================================================================================================

## Заключение  
Подводя итог, для разработки самообучающейся AI-модели, решающей перечисленные задачи, рекомендуется комбинированный подход. 
**Архитектура модели** должна быть гибкой: использовать мощь трансформеров для понимания текста и отвечать на вопросы, 
применять проверенные алгоритмы для табличных данных (с возможностью замены на современные нейросетевые модели при росте 
данных), и предусматривать модульность, чтобы каждая часть могла эволюционировать независимо. **Инструментарий** существует 
зрелый: фреймворки PyTorch и HuggingFace облегчат работу с NLP, библиотеки XGBoost/LightGBM – с табличными данными, а 
AutoML-системы позволят быстро прототипировать решения. Критически важно встроить механизм **автоматического обучения** на 
новых данных: через псевдо-разметку, активное обучение и непрерывное обучение модель сможет адаптироваться к меняющимся 
данным практически без ручного труда. Наконец, **MLOps-практики** (мониторинг, Continuous Training, автоматическое 
развертывание) обеспечат поддержание модели в актуальном состоянии и масштабируемость в продакшен-среде, позволяя системе 
работать надежно даже при значительном изменении входных данных или требований. Такая интегрированная система удовлетворит 
требованиям пользователя: максимальная автономность обучения, точность на текстовых и структурированных данных, и способность 
со временем становиться только лучше, учась на новом опыте.  

**Sources:** Использованы открытые данные и рекомендации из сообществ по состоянию на 2025 год, включая документацию 
HuggingFace ([Text classification](https://huggingface.co/docs/transformers/en/tasks/sequence_classification#:~:text=Text%20classification%20is%20a%20common,assigns%20a%20label%20like%20positive)), 
Medium-обзоры по self-learning ([Pseudo Labeling: Leveraging the Power of Self-Supervision in Machine Learning | by Data Overload | Medium](https://medium.com/@data-overload/pseudo-labeling-leveraging-the-power-of-self-supervision-in-machine-learning-d8192e918d65#:~:text=Pseudo%20labeling%2C%20also%20known%20as,predictions%20and%20improve%20over%20time)), 
материалы по MLOps ([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=Model%20retraining%20refers%20to%20updating,date%20data)) ([Model Retraining in 2025: Why & How to Retrain ML Models?](https://research.aimultiple.com/model-retraining/#:~:text=There%20are%20two%20main%20model,drift%20types)) 
и другие авторитетные ресурсы.